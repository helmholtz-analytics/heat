{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What is Heat for?\n",
    "\n",
    "\n",
    "\n",
    "Straight from our [GitHub repository](https://github.com/helmholtz-analytics/heat):\n",
    "\n",
    "Heat builds on [PyTorch](https://pytorch.org/) and [mpi4py](https://mpi4py.readthedocs.io) to provide high-performance computing infrastructure for memory-intensive applications within the NumPy/SciPy ecosystem.\n",
    "\n",
    "\n",
    "With Heat you can:\n",
    "- port existing NumPy/SciPy code from single-CPU to multi-node clusters with minimal coding effort;\n",
    "- exploit the entire, cumulative RAM of your many nodes for memory-intensive operations and algorithms;\n",
    "- run your NumPy/SciPy code on GPUs (CUDA, ROCm, limited support of Apple MPS).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?\n",
    "\n",
    "- significant **scalability** with respect to task-parallel frameworks;\n",
    "- analysis of massive datasets without breaking them up in artificially independent chunks;\n",
    "- ease of use: script and test on your laptop, port straight to HPC cluster; \n",
    "- PyTorch-based: GPU support beyond the CUDA ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=https://raw.githubusercontent.com/helmholtz-analytics/heat/master/doc/source/_static/images/heatvsdask_strong_smalldata_without.png?raw=true title=\"Strong scaling CPU\" width=\"30%\" style=\"float:center\"/>\n",
    "  <img src=https://raw.githubusercontent.com/helmholtz-analytics/heat/master/doc/source/_static/images/heatvsdask_weak_smalldata_without.png?raw=true title=\"Weak scaling CPU\" width=\"30%\" style=\"float:center \"/>\n",
    "  <img src=https://raw.githubusercontent.com/helmholtz-analytics/heat/master/doc/source/_static/images/weak_scaling_gpu_terrabyte.png?raw=true title=\"Weak scaling GPU\" width=\"30%\" style=\"float:center\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to ipyparallel cluster\n",
    "\n",
    "We have started an `ipcluster` with 4 engines at the end of the [Setup notebook](0_setup/0_setup_local.ipynb).\n",
    "\n",
    "Let's start the interactive session with a look into the `heat` data object. But first, we need to import the `ipyparallel` client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 engines found\n"
     ]
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "rc = Client(profile=\"default\")\n",
    "rc.ids\n",
    "\n",
    "if len(rc.ids) == 0:\n",
    "    print(\"No engines found\")\n",
    "else:\n",
    "    print(f\"{len(rc.ids)} engines found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will always start `heat` cells with the `%%px` magic command to execute the cell on all engines. However, the first section of this tutorial doesn't deal with distributed arrays. In these cases, we will use the `%%px --target 0` magic command to execute the cell only on the first engine.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNDarrays\n",
    "\n",
    "\n",
    "Similar to a NumPy `ndarray`, a Heat `dndarray`  (we'll get to the `d` later) is a grid of values of a single (one particular) type. The number of dimensions is the number of axes of the array, while the shape of an array is a tuple of integers giving the number of elements of the array along each dimension. \n",
    "\n",
    "Heat emulates NumPy's API as closely as possible, allowing for the use of well-known **array creation functions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e49353486a4ec5b84c5718033ed9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/4 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1f283774-7944c3bff18cf904e3c744da",
      "error": null,
      "execute_input": "import heat as ht\na = ht.array([1, 2, 3])\na\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:33.530025Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 3,
      "engine_uuid": "6ba7607d-e04b564e1775d69954ce923e",
      "error": null,
      "execute_input": "import heat as ht\na = ht.array([1, 2, 3])\na\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:33.530360Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:1]: \u001b[0mDNDarray([1, 2, 3], dtype=ht.int64, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "import heat as ht\na = ht.array([1, 2, 3])\na\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([1, 2, 3], dtype=ht.int64, device=cpu:0, split=None)"
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:33.529817Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 2,
      "engine_uuid": "92c8e04b-51a47e4da9184bf5101ea3b3",
      "error": null,
      "execute_input": "import heat as ht\na = ht.array([1, 2, 3])\na\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:33.530200Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px \n",
    "import heat as ht\n",
    "a = ht.array([1, 2, 3])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "a = ht.ones((4, 5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:3]: \u001b[0mDNDarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "ht.arange(10)\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=ht.int32, device=cpu:0, split=None)"
       },
       "execution_count": 3,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:45.922663Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "ht.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:4]: \u001b[0m\n",
       "DNDarray([[9., 9.],\n",
       "          [9., 9.],\n",
       "          [9., 9.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "ht.full((3, 2,), fill_value=9)\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([[9., 9.],\n          [9., 9.],\n          [9., 9.]], dtype=ht.float32, device=cpu:0, split=None)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:46.050829Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "ht.full((3, 2,), fill_value=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "Heat supports various data types and operations to retrieve and manipulate the type of a Heat array. However, in contrast to NumPy, Heat is limited to logical (bool) and numerical types (uint8, int16/32/64, float32/64, and complex64/128). \n",
    "\n",
    "**NOTE:** by default, Heat will allocate floating-point values in single precision, due to a much higher processing performance on GPUs. This is one of the main differences between Heat and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:5]: \u001b[0m\n",
       "DNDarray([[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a = ht.zeros((3, 4,))\na\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([[0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]], dtype=ht.float32, device=cpu:0, split=None)"
       },
       "execution_count": 5,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:46.176160Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "a = ht.zeros((3, 4,))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:6]: \u001b[0m\n",
       "DNDarray([[0, 0, 0, 0],\n",
       "          [0, 0, 0, 0],\n",
       "          [0, 0, 0, 0]], dtype=ht.int64, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "b = a.astype(ht.int64)\nb\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([[0, 0, 0, 0],\n          [0, 0, 0, 0],\n          [0, 0, 0, 0]], dtype=ht.int64, device=cpu:0, split=None)"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:46.307232Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "b = a.astype(ht.int64)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "Heat supports many mathematical operations, ranging from simple element-wise functions, binary arithmetic operations, and linear algebra, to more powerful reductions. Operations are by default performed on the entire array or they can be performed along one or more of its dimensions when available. Most relevant for data-intensive applications is that **all Heat functionalities support memory-distributed computation and GPU acceleration**. This holds for all operations, including reductions, statistics, linear algebra, and high-level algorithms. \n",
    "\n",
    "You can try out the few simple examples below if you want, but we will skip to the [Parallel Processing](#Parallel-Processing) section to see memory-distributed operations in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "a = ht.full((3, 4,), 8)\n",
    "b = ht.ones((3, 4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:8]: \u001b[0m\n",
       "DNDarray([[9., 9., 9., 9.],\n",
       "          [9., 9., 9., 9.],\n",
       "          [9., 9., 9., 9.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a + b\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([[9., 9., 9., 9.],\n          [9., 9., 9., 9.],\n          [9., 9., 9., 9.]], dtype=ht.float32, device=cpu:0, split=None)"
       },
       "execution_count": 8,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:46.818474Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:9]: \u001b[0m\n",
       "DNDarray([[7., 7., 7., 7.],\n",
       "          [7., 7., 7., 7.],\n",
       "          [7., 7., 7., 7.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "ht.sub(a, b)\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([[7., 7., 7., 7.],\n          [7., 7., 7., 7.],\n          [7., 7., 7., 7.]], dtype=ht.float32, device=cpu:0, split=None)"
       },
       "execution_count": 9,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:46.944208Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "ht.sub(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:10]: \u001b[0mDNDarray([ 0.0000,  0.8415,  0.9093,  0.1411, -0.7568], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "ht.arange(5).sin()\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([ 0.0000,  0.8415,  0.9093,  0.1411, -0.7568], dtype=ht.float32, device=cpu:0, split=None)"
       },
       "execution_count": 10,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:47.057469Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "ht.arange(5).sin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:11]: \u001b[0m\n",
       "DNDarray([[8., 8., 8.],\n",
       "          [8., 8., 8.],\n",
       "          [8., 8., 8.],\n",
       "          [8., 8., 8.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a.T\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([[8., 8., 8.],\n          [8., 8., 8.],\n          [8., 8., 8.],\n          [8., 8., 8.]], dtype=ht.float32, device=cpu:0, split=None)"
       },
       "execution_count": 11,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:47.178568Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:12]: \u001b[0mDNDarray([4., 4., 4.], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "b.sum(axis=1)\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([4., 4., 4.], dtype=ht.float32, device=cpu:0, split=None)"
       },
       "execution_count": 12,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:47.324713Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "b.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Heat implements the same broadcasting rules (implicit repetion of an operation when the rank/shape of the operands do not match) as NumPy does, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:13]: \u001b[0mDNDarray([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "ht.arange(10) + 3\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=ht.int32, device=cpu:0, split=None)"
       },
       "execution_count": 13,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:47.436007Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "ht.arange(10) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:14]: \u001b[0m\n",
       "(DNDarray([[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]], dtype=ht.float32, device=cpu:0, split=None),\n",
       " DNDarray([0, 1, 2, 3], dtype=ht.int32, device=cpu:0, split=None),\n",
       " DNDarray([[1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.]], dtype=ht.float32, device=cpu:0, split=None))"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a = ht.ones((3, 4,))\nb = ht.arange(4)\nc = a + b\n\na, b, c\n",
      "execute_result": {
       "data": {
        "text/plain": "(DNDarray([[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]], dtype=ht.float32, device=cpu:0, split=None),\n DNDarray([0, 1, 2, 3], dtype=ht.int32, device=cpu:0, split=None),\n DNDarray([[1., 2., 3., 4.],\n          [1., 2., 3., 4.],\n          [1., 2., 3., 4.]], dtype=ht.float32, device=cpu:0, split=None))"
       },
       "execution_count": 14,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:47.639454Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "a = ht.ones((3, 4,))\n",
    "b = ht.arange(4)\n",
    "c = a + b\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Heat allows the indexing of arrays, and thereby, the extraction of a partial view of the elements in an array. It is possible to obtain single values as well as entire chunks, i.e. slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:15]: \u001b[0mDNDarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a = ht.arange(10)\na\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=ht.int32, device=cpu:0, split=None)"
       },
       "execution_count": 15,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.008176Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-26T13:23:48.027255Z",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1f283774-7944c3bff18cf904e3c744da",
      "error": null,
      "execute_input": "a = ht.arange(10)\na\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0417f370-73d37041a9ac2531bf7eba83_117201_19",
      "outputs": [],
      "received": "2025-05-26T13:23:48.029808Z",
      "started": "2025-05-26T13:23:48.017162Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.008542Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 3,
      "engine_uuid": "6ba7607d-e04b564e1775d69954ce923e",
      "error": null,
      "execute_input": "a = ht.arange(10)\na\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.009226Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 2,
      "engine_uuid": "92c8e04b-51a47e4da9184bf5101ea3b3",
      "error": null,
      "execute_input": "a = ht.arange(10)\na\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.009103Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "a = ht.arange(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1f283774-7944c3bff18cf904e3c744da",
      "error": null,
      "execute_input": "a[3]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 3,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.161611Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 3,
      "engine_uuid": "6ba7607d-e04b564e1775d69954ce923e",
      "error": null,
      "execute_input": "a[3]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 3,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.161996Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 2,
      "engine_uuid": "92c8e04b-51a47e4da9184bf5101ea3b3",
      "error": null,
      "execute_input": "a[3]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 3,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.161808Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:16]: \u001b[0mDNDarray(3, dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-26T13:23:48.191783Z",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a[3]\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray(3, dtype=ht.int32, device=cpu:0, split=None)"
       },
       "execution_count": 16,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0417f370-73d37041a9ac2531bf7eba83_117201_22",
      "outputs": [],
      "received": "2025-05-26T13:23:48.201000Z",
      "started": "2025-05-26T13:23:48.171724Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.161033Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:17]: \u001b[0mDNDarray([1, 2, 3, 4, 5, 6], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-26T13:23:48.347178Z",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a[1:7]\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([1, 2, 3, 4, 5, 6], dtype=ht.int32, device=cpu:0, split=None)"
       },
       "execution_count": 17,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0417f370-73d37041a9ac2531bf7eba83_117201_26",
      "outputs": [],
      "received": "2025-05-26T13:23:48.358342Z",
      "started": "2025-05-26T13:23:48.338556Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.330525Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-26T13:23:48.349166Z",
      "data": {},
      "engine_id": 3,
      "engine_uuid": "6ba7607d-e04b564e1775d69954ce923e",
      "error": null,
      "execute_input": "a[1:7]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0417f370-73d37041a9ac2531bf7eba83_117201_29",
      "outputs": [],
      "received": "2025-05-26T13:23:48.359482Z",
      "started": "2025-05-26T13:23:48.342189Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.332068Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-26T13:23:48.356210Z",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1f283774-7944c3bff18cf904e3c744da",
      "error": null,
      "execute_input": "a[1:7]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0417f370-73d37041a9ac2531bf7eba83_117201_27",
      "outputs": [],
      "received": "2025-05-26T13:23:48.360588Z",
      "started": "2025-05-26T13:23:48.342414Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.331655Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-26T13:23:48.366525Z",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "92c8e04b-51a47e4da9184bf5101ea3b3",
      "error": null,
      "execute_input": "a[1:7]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0417f370-73d37041a9ac2531bf7eba83_117201_28",
      "outputs": [],
      "received": "2025-05-26T13:23:48.369675Z",
      "started": "2025-05-26T13:23:48.348209Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.331903Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "a[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:18]: \u001b[0mDNDarray([0, 2, 4, 6, 8], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "0baec09a-557ac92cbb4d09ae53564756",
      "error": null,
      "execute_input": "a[::2]\n",
      "execute_result": {
       "data": {
        "text/plain": "DNDarray([0, 2, 4, 6, 8], dtype=ht.int32, device=cpu:0, split=None)"
       },
       "execution_count": 18,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.484327Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 3,
      "engine_uuid": "6ba7607d-e04b564e1775d69954ce923e",
      "error": null,
      "execute_input": "a[::2]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 5,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.484970Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1f283774-7944c3bff18cf904e3c744da",
      "error": null,
      "execute_input": "a[::2]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 5,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.484586Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-26T13:23:48.500203Z",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "92c8e04b-51a47e4da9184bf5101ea3b3",
      "error": null,
      "execute_input": "a[::2]\n",
      "execute_result": {
       "data": {
        "text/plain": ""
       },
       "execution_count": 5,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0417f370-73d37041a9ac2531bf7eba83_117201_32",
      "outputs": [],
      "received": "2025-05-26T13:23:48.512685Z",
      "started": "2025-05-26T13:23:48.494409Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-26T13:23:48.484659Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "a[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Indexing in Heat is undergoing a [major overhaul](https://github.com/helmholtz-analytics/heat/pull/938), to increase interoperability with NumPy/PyTorch indexing, and to provide a fully distributed item setting functionality. Stay tuned for this feature in the next release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Heat is extensively documented. You may find the online API reference on Read the Docs: [Heat Documentation](https://heat.readthedocs.io/). It is also possible to look up the docs in an interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Help on function sum in module heat.core.arithmetics:\n",
       "\n",
       "sum(a: 'DNDarray', axis: 'Union[int, Tuple[int, ...]]' = None, out: 'DNDarray' = None, keepdims: 'bool' = None) -> 'DNDarray'\n",
       "    Sum of array elements over a given axis. An array with the same shape as ``self.__array`` except\n",
       "    for the specified axis which becomes one, e.g.\n",
       "    ``a.shape=(1, 2, 3)`` => ``ht.ones((1, 2, 3)).sum(axis=1).shape=(1, 1, 3)``\n",
       "    \n",
       "    Parameters\n",
       "    ----------\n",
       "    a : DNDarray\n",
       "        Input array.\n",
       "    axis : None or int or Tuple[int,...], optional\n",
       "        Axis along which a sum is performed. The default, ``axis=None``, will sum all of the\n",
       "        elements of the input array. If ``axis`` is negative it counts from the last to the first\n",
       "        axis. If ``axis`` is a tuple of ints, a sum is performed on all of the axes specified in the\n",
       "        tuple instead of a single axis or all the axes as before.\n",
       "    out : DNDarray, optional\n",
       "        Alternative output array in which to place the result. It must have the same shape as the\n",
       "        expected output, but the datatype of the output values will be cast if necessary.\n",
       "    keepdims : bool, optional\n",
       "        If this is set to ``True``, the axes which are reduced are left in the result as dimensions\n",
       "        with size one. With this option, the result will broadcast correctly against the input\n",
       "        array.\n",
       "    \n",
       "    Examples\n",
       "    --------\n",
       "    >>> ht.sum(ht.ones(2))\n",
       "    DNDarray(2., dtype=ht.float32, device=cpu:0, split=None)\n",
       "    >>> ht.sum(ht.ones((3,3)))\n",
       "    DNDarray(9., dtype=ht.float32, device=cpu:0, split=None)\n",
       "    >>> ht.sum(ht.ones((3,3)).astype(ht.int))\n",
       "    DNDarray(9, dtype=ht.int64, device=cpu:0, split=None)\n",
       "    >>> ht.sum(ht.ones((3,2,1)), axis=-3)\n",
       "    DNDarray([[3.],\n",
       "              [3.]], dtype=ht.float32, device=cpu:0, split=None)\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "help(ht.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing\n",
    "\n",
    "Heat's actual power lies in the possibility to exploit the processing performance of modern accelerator hardware (GPUs) as well as distributed (high-performance) cluster systems. All operations executed on CPUs are, to a large extent, vectorized (AVX) and thread-parallelized (OpenMP). Heat builds on PyTorch, so it supports GPU acceleration on Nvidia and AMD GPUs. \n",
    "\n",
    "For distributed computations, your system or laptop needs to have Message Passing Interface (MPI) installed. For GPU computations, your system needs to have one or more suitable GPUs and (MPI-aware) CUDA/ROCm ecosystem.\n",
    "\n",
    "**NOTE:** The GPU examples below will only properly execute on a computer with a GPU. Make sure to either start the notebook on an appropriate machine or copy and paste the examples into a script and execute it on a suitable device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUs\n",
    "\n",
    "Heat's array creation functions all support an additional parameter that which places the data on a specific device. By default, the CPU is selected, but it is also possible to directly allocate the data on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>The following cells will only work if you have a GPU available.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:execute]\n",
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/devices.py:190\u001b[39m, in \u001b[36msanitize_device\u001b[39m\u001b[34m(device)\u001b[39m\n",
      "\u001b[32m    189\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__device_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m    191\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'gpu'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mht\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/factories.py:1489\u001b[39m, in \u001b[36mzeros\u001b[39m\u001b[34m(shape, dtype, split, device, comm, order)\u001b[39m\n",
      "\u001b[32m   1451\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m   1452\u001b[39m \u001b[33;03mReturns a new :class:`~heat.core.dndarray.DNDarray` of given shape and data type filled with zero values.\u001b[39;00m\n",
      "\u001b[32m   1453\u001b[39m \u001b[33;03mMay be allocated split up across multiple nodes along the specified axis.\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m   1486\u001b[39m \u001b[33;03m          [0., 0., 0.]], dtype=ht.float32, device=cpu:0, split=None)\u001b[39;00m\n",
      "\u001b[32m   1487\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m   1488\u001b[39m \u001b[38;5;66;03m# TODO: implement 'K' option when torch.clone() fix to preserve memory layout is released.\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1489\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/factories.py:763\u001b[39m, in \u001b[36m__factory\u001b[39m\u001b[34m(shape, dtype, split, local_factory, device, comm, order)\u001b[39m\n",
      "\u001b[32m    761\u001b[39m dtype = types.canonical_heat_type(dtype)\n",
      "\u001b[32m    762\u001b[39m split = sanitize_axis(shape, split)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m device = \u001b[43mdevices\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    764\u001b[39m comm = sanitize_comm(comm)\n",
      "\u001b[32m    766\u001b[39m \u001b[38;5;66;03m# chunk the shape if necessary\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/devices.py:192\u001b[39m, in \u001b[36msanitize_device\u001b[39m\u001b[34m(device)\u001b[39m\n",
      "\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m __device_mapping[device.strip().lower()]\n",
      "\u001b[32m    191\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnknown device, must be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(__device_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[31mValueError\u001b[39m: Unknown device, must be one of cpu\n"
     ]
    },
    {
     "ename": "RemoteError",
     "evalue": "[0:execute] ValueError: Unknown device, must be one of cpu",
     "output_type": "error",
     "traceback": [
      "[0:execute]",
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/devices.py:190\u001b[39m, in \u001b[36msanitize_device\u001b[39m\u001b[34m(device)\u001b[39m",
      "\u001b[32m    189\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:",
      "\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__device_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m",
      "\u001b[32m    191\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):",
      "",
      "\u001b[31mKeyError\u001b[39m: 'gpu'",
      "",
      "During handling of the above exception, another exception occurred:",
      "",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mht\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/factories.py:1489\u001b[39m, in \u001b[36mzeros\u001b[39m\u001b[34m(shape, dtype, split, device, comm, order)\u001b[39m",
      "\u001b[32m   1451\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m",
      "\u001b[32m   1452\u001b[39m \u001b[33;03mReturns a new :class:`~heat.core.dndarray.DNDarray` of given shape and data type filled with zero values.\u001b[39;00m",
      "\u001b[32m   1453\u001b[39m \u001b[33;03mMay be allocated split up across multiple nodes along the specified axis.\u001b[39;00m",
      "\u001b[32m   (...)\u001b[39m\u001b[32m   1486\u001b[39m \u001b[33;03m          [0., 0., 0.]], dtype=ht.float32, device=cpu:0, split=None)\u001b[39;00m",
      "\u001b[32m   1487\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m",
      "\u001b[32m   1488\u001b[39m \u001b[38;5;66;03m# TODO: implement 'K' option when torch.clone() fix to preserve memory layout is released.\u001b[39;00m",
      "\u001b[32m-> \u001b[39m\u001b[32m1489\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/factories.py:763\u001b[39m, in \u001b[36m__factory\u001b[39m\u001b[34m(shape, dtype, split, local_factory, device, comm, order)\u001b[39m",
      "\u001b[32m    761\u001b[39m dtype = types.canonical_heat_type(dtype)",
      "\u001b[32m    762\u001b[39m split = sanitize_axis(shape, split)",
      "\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m device = \u001b[43mdevices\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m    764\u001b[39m comm = sanitize_comm(comm)",
      "\u001b[32m    766\u001b[39m \u001b[38;5;66;03m# chunk the shape if necessary\u001b[39;00m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/heat/heat/core/devices.py:192\u001b[39m, in \u001b[36msanitize_device\u001b[39m\u001b[34m(device)\u001b[39m",
      "\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m __device_mapping[device.strip().lower()]",
      "\u001b[32m    191\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):",
      "\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnknown device, must be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(__device_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)",
      "",
      "\u001b[31mValueError\u001b[39m: Unknown device, must be one of cpu"
     ]
    }
   ],
   "source": [
    "%%px --target 0\n",
    "ht.zeros((3, 4,), device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays on the same device can be seamlessly used in any Heat operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:21]: \u001b[0m<DNDarray(MPI-rank: 0, Shape: (3, 4), Split: None, Local Shape: (3, 4), Device: gpu:0, Dtype: float32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "26ba0021-35d3d060b50582f7d11d6ead",
      "error": null,
      "execute_input": "a = ht.zeros((3, 4,), device='gpu')\nb = ht.ones((3, 4,), device='gpu')\na + b\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 0, Shape: (3, 4), Split: None, Local Shape: (3, 4), Device: gpu:0, Dtype: float32)>"
       },
       "execution_count": 21,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:40.413421Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "a = ht.zeros((3, 4,), device='gpu')\n",
    "b = ht.ones((3, 4,), device='gpu')\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, performing operations on arrays with mismatching devices will purposefully result in an error (due to potentially large copy overhead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m ht\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m,), \u001b[38;5;241m4\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m ht\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m,), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/code/heat/heat/core/arithmetics.py:124\u001b[0m, in \u001b[0;36m_add\u001b[0;34m(self, other)\u001b[0m\n",
      "\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n",
      "\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/code/heat/heat/core/arithmetics.py:119\u001b[0m, in \u001b[0;36madd\u001b[0;34m(t1, t2, out, where)\u001b[0m\n",
      "\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\n",
      "\u001b[1;32m     75\u001b[0m     t1: Union[DNDarray, \u001b[38;5;28mfloat\u001b[39m],\n",
      "\u001b[1;32m     76\u001b[0m     t2: Union[DNDarray, \u001b[38;5;28mfloat\u001b[39m],\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     80\u001b[0m     where: Union[\u001b[38;5;28mbool\u001b[39m, DNDarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[1;32m     81\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DNDarray:\n",
      "\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Element-wise addition of values from two operands, commutative.\u001b[39;00m\n",
      "\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Takes the first and second operand (scalar or :class:`~heat.core.dndarray.DNDarray`) whose\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m              [5., 6.]], dtype=ht.float32, device=cpu:0, split=None)\u001b[39;00m\n",
      "\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_operations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/code/heat/heat/core/_operations.py:204\u001b[0m, in \u001b[0;36m__binary_op\u001b[0;34m(operation, t1, t2, out, where, fn_kwargs)\u001b[0m\n",
      "\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t1\u001b[38;5;241m.\u001b[39mlarray\u001b[38;5;241m.\u001b[39mis_mps \u001b[38;5;129;01mand\u001b[39;00m promoted_type \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat64:\n",
      "\u001b[1;32m    202\u001b[0m     promoted_type \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32\n",
      "\u001b[0;32m--> 204\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpromoted_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpromoted_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DNDarray(\n",
      "\u001b[1;32m    208\u001b[0m         result,\n",
      "\u001b[1;32m    209\u001b[0m         output_shape,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    214\u001b[0m         balanced\u001b[38;5;241m=\u001b[39moutput_balanced,\n",
      "\u001b[1;32m    215\u001b[0m     )\n",
      "\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    },
    {
     "ename": "RemoteError",
     "evalue": "[0:execute] RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "[0:execute]",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m",
      "\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m ht\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m,), \u001b[38;5;241m4\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)",
      "\u001b[1;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m ht\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m,), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m)",
      "\u001b[0;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m",
      "",
      "File \u001b[0;32m~/code/heat/heat/core/arithmetics.py:124\u001b[0m, in \u001b[0;36m_add\u001b[0;34m(self, other)\u001b[0m",
      "\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):",
      "\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:",
      "\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:",
      "\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m",
      "",
      "File \u001b[0;32m~/code/heat/heat/core/arithmetics.py:119\u001b[0m, in \u001b[0;36madd\u001b[0;34m(t1, t2, out, where)\u001b[0m",
      "\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(",
      "\u001b[1;32m     75\u001b[0m     t1: Union[DNDarray, \u001b[38;5;28mfloat\u001b[39m],",
      "\u001b[1;32m     76\u001b[0m     t2: Union[DNDarray, \u001b[38;5;28mfloat\u001b[39m],",
      "\u001b[0;32m   (...)\u001b[0m",
      "\u001b[1;32m     80\u001b[0m     where: Union[\u001b[38;5;28mbool\u001b[39m, DNDarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,",
      "\u001b[1;32m     81\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DNDarray:",
      "\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m",
      "\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Element-wise addition of values from two operands, commutative.\u001b[39;00m",
      "\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Takes the first and second operand (scalar or :class:`~heat.core.dndarray.DNDarray`) whose\u001b[39;00m",
      "\u001b[0;32m   (...)\u001b[0m",
      "\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m              [5., 6.]], dtype=ht.float32, device=cpu:0, split=None)\u001b[39;00m",
      "\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m",
      "\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_operations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "File \u001b[0;32m~/code/heat/heat/core/_operations.py:204\u001b[0m, in \u001b[0;36m__binary_op\u001b[0;34m(operation, t1, t2, out, where, fn_kwargs)\u001b[0m",
      "\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t1\u001b[38;5;241m.\u001b[39mlarray\u001b[38;5;241m.\u001b[39mis_mps \u001b[38;5;129;01mand\u001b[39;00m promoted_type \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat64:",
      "\u001b[1;32m    202\u001b[0m     promoted_type \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32",
      "\u001b[0;32m--> 204\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpromoted_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpromoted_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:",
      "\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DNDarray(",
      "\u001b[1;32m    208\u001b[0m         result,",
      "\u001b[1;32m    209\u001b[0m         output_shape,",
      "\u001b[0;32m   (...)\u001b[0m",
      "\u001b[1;32m    214\u001b[0m         balanced\u001b[38;5;241m=\u001b[39moutput_balanced,",
      "\u001b[1;32m    215\u001b[0m     )",
      "",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "%%px --target 0\n",
    "a = ht.full((3, 4,), 4, device='cpu')\n",
    "b = ht.ones((3, 4,), device='gpu')\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to explicitly move an array from one device to the other and back to avoid this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:23]: \u001b[0m<DNDarray(MPI-rank: 0, Shape: (3, 4), Split: None, Local Shape: (3, 4), Device: cpu:0, Dtype: float32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "26ba0021-35d3d060b50582f7d11d6ead",
      "error": null,
      "execute_input": "a = ht.full((3, 4,), 4, device='gpu')\na.cpu()\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 0, Shape: (3, 4), Split: None, Local Shape: (3, 4), Device: cpu:0, Dtype: float32)>"
       },
       "execution_count": 23,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.011333Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --target 0\n",
    "a = ht.full((3, 4,), 4, device='gpu')\n",
    "a.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put our multi-GPU setup to the test in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Computing\n",
    "\n",
    "Heat is also able to make use of distributed processing capabilities such as those in high-performance cluster systems. For this, Heat exploits the fact that the operations performed on a multi-dimensional array are usually identical for all data items. Hence, a data-parallel processing strategy can be chosen, where the total number of data items is equally divided among all processing nodes. An operation is then performed individually on the local data chunks and, if necessary, communicates partial results behind the scenes. A Heat array assumes the role of a virtual overlay of the local chunks and realizes and coordinates the computations - see the figure below for a visual representation of this concept.\n",
    "\n",
    "<img src=\"https://github.com/helmholtz-analytics/heat/blob/main/doc/source/_static/images/split_array.png?raw=true\" width=\"100%\"></img>\n",
    "\n",
    "The chunks are always split along a singular dimension (i.e. 1-D domain decomposition) of the array. You can specify this in Heat by using the `split` paramter. This parameter is present in all relevant functions, such as array creation (`zeros(), ones(), ...`) or I/O (`load()`) functions. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Examples are provided below. The result of an operation on a Heat tensor will in most cases preserve the split of the respective operands. However, in some cases the split axis might change. For example, a transpose of a Heat array will equally transpose the split axis. Furthermore, a reduction operations, e.g. `sum()` that is performed across the split axis, might remove data partitions entirely. The respective function behaviors can be found in Heat's documentation.\n",
    "\n",
    "You may also modify the data partitioning of a Heat array by using the `resplit()` function. This allows you to repartition the data as you so choose. Please note, that this should be used sparingly and for small data amounts only, as it entails significant data copying across the network. Finally, a Heat array without any split, i.e. `split=None` (default), will result in redundant copies of data on each computation node.\n",
    "\n",
    "On a technical level, Heat follows the so-called [Bulk Synchronous Parallel (BSP)](https://en.wikipedia.org/wiki/Bulk_synchronous_parallel) processing model. For the network communication, Heat utilizes the [Message Passing Interface (MPI)](https://computing.llnl.gov/tutorials/mpi/), a *de facto* standard on modern high-performance computing systems. It is also possible to use MPI on your laptop or desktop computer. Respective software packages are available for all major operating systems. In order to run a Heat script, you need to start it slightly differently than you are probably used to. This\n",
    "\n",
    "```bash\n",
    "python ./my_script.py\n",
    "```\n",
    "\n",
    "becomes this instead:\n",
    "\n",
    "```bash\n",
    "mpirun -n <number_of_processors> python ./my_script.py\n",
    "```\n",
    "On an HPC cluster you'll of course use SBATCH or similar.\n",
    "\n",
    "\n",
    "Let's see some examples of working with distributed Heat:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following examples, we'll recreate the array shown in the figure, a 3-dimensional DNDarray of integers ranging from 0 to 59 (5 matrices of size (4,3)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:6]: \u001b[0m<DNDarray(MPI-rank: 1, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 1,
      "engine_uuid": "4a6ffcbf-4b7c9961beb0aa49f4f299a5",
      "error": null,
      "execute_input": "import heat as ht\ndndarray = ht.arange(60).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 1, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.052126Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:6]: \u001b[0m<DNDarray(MPI-rank: 2, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 2,
      "engine_uuid": "e3e9e719-1b11a826b66969f71d179e21",
      "error": null,
      "execute_input": "import heat as ht\ndndarray = ht.arange(60).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 2, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.052193Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:24]: \u001b[0m<DNDarray(MPI-rank: 0, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "26ba0021-35d3d060b50582f7d11d6ead",
      "error": null,
      "execute_input": "import heat as ht\ndndarray = ht.arange(60).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 0, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 24,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.052033Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[3:6]: \u001b[0m<DNDarray(MPI-rank: 3, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.061012Z",
      "data": {},
      "engine_id": 3,
      "engine_uuid": "b9f6f6e8-01c224a4024814eaffce2266",
      "error": null,
      "execute_input": "import heat as ht\ndndarray = ht.arange(60).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 3, Shape: (5, 4, 3), Split: None, Local Shape: (5, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_42",
      "outputs": [],
      "received": "2025-05-19T19:17:51.067009Z",
      "started": "2025-05-19T19:17:51.055404Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.052218Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import heat as ht\n",
    "dndarray = ht.arange(60).reshape(5,4,3)\n",
    "dndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the additional metadata printed with the DNDarray. With respect to a numpy ndarray, the DNDarray has additional information on the device (in this case, the CPU) and the `split` axis. In the example above, the split axis is `None`, meaning that the DNDarray is not distributed and each MPI process has a full copy of the data.\n",
    "\n",
    "Let's experiment with a distributed DNDarray: we'll split the same DNDarray as above, but distributed along the major axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:7]: \u001b[0m<DNDarray(MPI-rank: 1, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 1,
      "engine_uuid": "4a6ffcbf-4b7c9961beb0aa49f4f299a5",
      "error": null,
      "execute_input": "dndarray = ht.arange(60, split=0).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 1, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 7,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.106705Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:25]: \u001b[0m<DNDarray(MPI-rank: 0, Shape: (5, 4, 3), Split: 0, Local Shape: (2, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "26ba0021-35d3d060b50582f7d11d6ead",
      "error": null,
      "execute_input": "dndarray = ht.arange(60, split=0).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 0, Shape: (5, 4, 3), Split: 0, Local Shape: (2, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 25,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.106454Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[3:7]: \u001b[0m<DNDarray(MPI-rank: 3, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 3,
      "engine_uuid": "b9f6f6e8-01c224a4024814eaffce2266",
      "error": null,
      "execute_input": "dndarray = ht.arange(60, split=0).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 3, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 7,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.106872Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:7]: \u001b[0m<DNDarray(MPI-rank: 2, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 2,
      "engine_uuid": "e3e9e719-1b11a826b66969f71d179e21",
      "error": null,
      "execute_input": "dndarray = ht.arange(60, split=0).reshape(5,4,3)\ndndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 2, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 7,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.106799Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "dndarray = ht.arange(60, split=0).reshape(5,4,3)\n",
    "dndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `split` axis is now 0, meaning that the DNDarray is distributed along the first axis. Each MPI process has a slice of the data along the first axis. In order to see the data on each process, we can print the \"local array\" via the `larray` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:8]: \u001b[0m\n",
       "tensor([[[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]]], dtype=torch.int32)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.194662Z",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "4a6ffcbf-4b7c9961beb0aa49f4f299a5",
      "error": null,
      "execute_input": "dndarray.larray\n",
      "execute_result": {
       "data": {
        "text/plain": "tensor([[[24, 25, 26],\n         [27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]]], dtype=torch.int32)"
       },
       "execution_count": 8,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_48",
      "outputs": [],
      "received": "2025-05-19T19:17:51.198154Z",
      "started": "2025-05-19T19:17:51.190508Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.178849Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[3:8]: \u001b[0m\n",
       "tensor([[[48, 49, 50],\n",
       "         [51, 52, 53],\n",
       "         [54, 55, 56],\n",
       "         [57, 58, 59]]], dtype=torch.int32)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.194657Z",
      "data": {},
      "engine_id": 3,
      "engine_uuid": "b9f6f6e8-01c224a4024814eaffce2266",
      "error": null,
      "execute_input": "dndarray.larray\n",
      "execute_result": {
       "data": {
        "text/plain": "tensor([[[48, 49, 50],\n         [51, 52, 53],\n         [54, 55, 56],\n         [57, 58, 59]]], dtype=torch.int32)"
       },
       "execution_count": 8,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_50",
      "outputs": [],
      "received": "2025-05-19T19:17:51.197555Z",
      "started": "2025-05-19T19:17:51.191263Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.180344Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:26]: \u001b[0m\n",
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]]], dtype=torch.int32)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.195580Z",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "26ba0021-35d3d060b50582f7d11d6ead",
      "error": null,
      "execute_input": "dndarray.larray\n",
      "execute_result": {
       "data": {
        "text/plain": "tensor([[[ 0,  1,  2],\n         [ 3,  4,  5],\n         [ 6,  7,  8],\n         [ 9, 10, 11]],\n\n        [[12, 13, 14],\n         [15, 16, 17],\n         [18, 19, 20],\n         [21, 22, 23]]], dtype=torch.int32)"
       },
       "execution_count": 26,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_47",
      "outputs": [],
      "received": "2025-05-19T19:17:51.198806Z",
      "started": "2025-05-19T19:17:51.190353Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.178691Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:8]: \u001b[0m\n",
       "tensor([[[36, 37, 38],\n",
       "         [39, 40, 41],\n",
       "         [42, 43, 44],\n",
       "         [45, 46, 47]]], dtype=torch.int32)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.196655Z",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "e3e9e719-1b11a826b66969f71d179e21",
      "error": null,
      "execute_input": "dndarray.larray\n",
      "execute_result": {
       "data": {
        "text/plain": "tensor([[[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44],\n         [45, 46, 47]]], dtype=torch.int32)"
       },
       "execution_count": 8,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_49",
      "outputs": [],
      "received": "2025-05-19T19:17:51.204676Z",
      "started": "2025-05-19T19:17:51.191467Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.179122Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "dndarray.larray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `larray` is a `torch.Tensor` object. This is the underlying tensor that holds the data. The `dndarray` object is an MPI-aware wrapper around these process-local tensors, providing memory-distributed functionality and information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DNDarray can be distributed along any axis. Modify the `split` attribute when creating the DNDarray in the cell above, to distribute it along a different axis, and see how the `larray`s change. You'll notice that the distributed arrays are always load-balanced, meaning that the data are distributed as evenly as possible across the MPI processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DNDarray` object has a number of methods and attributes that are useful for distributed computing. In particular, it keeps track of its global and local (on a given process) shape through distributed operations and array manipulations. The DNDarray is also associated to a `comm` object, the MPI communicator.\n",
    "\n",
    "(In MPI, the *communicator* is a group of processes that can communicate with each other. The `comm` object is a `MPI.COMM_WORLD` communicator, which is the default communicator that includes all the processes. The `comm` object is used to perform collective operations, such as reductions, scatter, gather, and broadcast. The `comm` object is also used to perform point-to-point communication between processes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Global shape of the dndarray: (5, 4, 3)\n",
       "On rank 0/4, local shape of the dndarray: (2, 4, 3)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Global shape of the dndarray: (5, 4, 3)\n",
       "On rank 1/4, local shape of the dndarray: (1, 4, 3)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Global shape of the dndarray: (5, 4, 3)\n",
       "On rank 2/4, local shape of the dndarray: (1, 4, 3)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Global shape of the dndarray: (5, 4, 3)\n",
       "On rank 3/4, local shape of the dndarray: (1, 4, 3)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "print(f\"Global shape of the dndarray: {dndarray.shape}\")\n",
    "print(f\"On rank {dndarray.comm.rank}/{dndarray.comm.size}, local shape of the dndarray: {dndarray.lshape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform a vast number of operations on DNDarrays distributed over multi-node and/or multi-GPU resources. Check out our [Numpy coverage tables](https://github.com/helmholtz-analytics/heat/blob/main/coverage_tables.md) to see what operations are already supported.  \n",
    "\n",
    "The result of an operation on DNDarays will in most cases preserve the `split` or distribution axis of the respective operands. However, in some cases the split axis might change. For example, a transpose of a Heat array will equally transpose the split axis. Furthermore, a reduction operations, e.g. `sum()` that is performed across the split axis, might remove data partitions entirely. The respective function behaviors can be found in Heat's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:28]: \u001b[0m<DNDarray(MPI-rank: 0, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 2), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "26ba0021-35d3d060b50582f7d11d6ead",
      "error": null,
      "execute_input": "# transpose \ndndarray.T\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 0, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 2), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 28,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.287542Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:10]: \u001b[0m<DNDarray(MPI-rank: 2, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 1), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.294221Z",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "e3e9e719-1b11a826b66969f71d179e21",
      "error": null,
      "execute_input": "# transpose \ndndarray.T\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 2, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 1), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 10,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_57",
      "outputs": [],
      "received": "2025-05-19T19:17:51.297046Z",
      "started": "2025-05-19T19:17:51.290699Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.288331Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:10]: \u001b[0m<DNDarray(MPI-rank: 1, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 1), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.295026Z",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "4a6ffcbf-4b7c9961beb0aa49f4f299a5",
      "error": null,
      "execute_input": "# transpose \ndndarray.T\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 1, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 1), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 10,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_56",
      "outputs": [],
      "received": "2025-05-19T19:17:51.297591Z",
      "started": "2025-05-19T19:17:51.290440Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.288210Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[3:10]: \u001b[0m<DNDarray(MPI-rank: 3, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 1), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.296667Z",
      "data": {},
      "engine_id": 3,
      "engine_uuid": "b9f6f6e8-01c224a4024814eaffce2266",
      "error": null,
      "execute_input": "# transpose \ndndarray.T\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 3, Shape: (3, 4, 5), Split: 2, Local Shape: (3, 4, 1), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 10,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_58",
      "outputs": [],
      "received": "2025-05-19T19:17:51.300499Z",
      "started": "2025-05-19T19:17:51.293633Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.288398Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px \n",
    "# transpose \n",
    "dndarray.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] The slowest run took 31.60 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "504 µs ± 876 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] The slowest run took 28.84 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "501 µs ± 864 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] The slowest run took 29.75 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "503 µs ± 880 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] The slowest run took 8.36 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "237 µs ± 216 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "# reduction operation along the distribution axis\n",
    "%timeit -n 1 dndarray.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] The slowest run took 13.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "114 µs ± 141 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] 72.7 µs ± 32.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] 71.7 µs ± 35.8 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] The slowest run took 15.67 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "183 µs ± 291 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px \n",
    "# reduction operation along non-distribution axis: no communication required\n",
    "%timeit -n 1 dndarray.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations between tensors with equal split or no split are fully parallelizable and therefore very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:13]: \u001b[0m<DNDarray(MPI-rank: 1, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 1,
      "engine_uuid": "4a6ffcbf-4b7c9961beb0aa49f4f299a5",
      "error": null,
      "execute_input": "other_dndarray = ht.arange(60,120, split=0).reshape(5,4,3) # distributed reshape\n\n# element-wise multiplication\ndndarray * other_dndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 1, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 13,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.515462Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:31]: \u001b[0m<DNDarray(MPI-rank: 0, Shape: (5, 4, 3), Split: 0, Local Shape: (2, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": null,
      "completed": null,
      "data": {},
      "engine_id": 0,
      "engine_uuid": "26ba0021-35d3d060b50582f7d11d6ead",
      "error": null,
      "execute_input": "other_dndarray = ht.arange(60,120, split=0).reshape(5,4,3) # distributed reshape\n\n# element-wise multiplication\ndndarray * other_dndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 0, Shape: (5, 4, 3), Split: 0, Local Shape: (2, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 31,
       "metadata": {}
      },
      "follow": null,
      "msg_id": null,
      "outputs": [],
      "received": null,
      "started": null,
      "status": null,
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.514668Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[3:13]: \u001b[0m<DNDarray(MPI-rank: 3, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.529643Z",
      "data": {},
      "engine_id": 3,
      "engine_uuid": "b9f6f6e8-01c224a4024814eaffce2266",
      "error": null,
      "execute_input": "other_dndarray = ht.arange(60,120, split=0).reshape(5,4,3) # distributed reshape\n\n# element-wise multiplication\ndndarray * other_dndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 3, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 13,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_70",
      "outputs": [],
      "received": "2025-05-19T19:17:51.532912Z",
      "started": "2025-05-19T19:17:51.518984Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.516415Z"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:13]: \u001b[0m<DNDarray(MPI-rank: 2, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2025-05-19T19:17:51.529626Z",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "e3e9e719-1b11a826b66969f71d179e21",
      "error": null,
      "execute_input": "other_dndarray = ht.arange(60,120, split=0).reshape(5,4,3) # distributed reshape\n\n# element-wise multiplication\ndndarray * other_dndarray\n",
      "execute_result": {
       "data": {
        "text/plain": "<DNDarray(MPI-rank: 2, Shape: (5, 4, 3), Split: 0, Local Shape: (1, 4, 3), Device: cpu:0, Dtype: int32)>"
       },
       "execution_count": 13,
       "metadata": {}
      },
      "follow": [],
      "is_broadcast": false,
      "is_coalescing": false,
      "msg_id": "0799d273-c85f091368add7dbf88c8344_231252_69",
      "outputs": [],
      "received": "2025-05-19T19:17:51.534904Z",
      "started": "2025-05-19T19:17:51.522307Z",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2025-05-19T19:17:51.516241Z"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "other_dndarray = ht.arange(60,120, split=0).reshape(5,4,3) # distributed reshape\n",
    "\n",
    "# element-wise multiplication\n",
    "dndarray * other_dndarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, because the underlying data objects are PyTorch tensors, we can easily create DNDarrays on GPUs or move DNDarrays to GPUs. This allows us to perform distributed array operations on multi-GPU systems.\n",
    "\n",
    "So far we have demostrated small, easy-to-parallelize arithmetical operations. Let's move to linear algebra. Heat's `linalg` module supports a wide range of linear algebra operations, including matrix multiplication. Matrix multiplication is a very common operation data analysis, it is computationally intensive, and not trivial to parallelize. \n",
    "\n",
    "With Heat, you can perform matrix multiplication on distributed DNDarrays, and the operation will be parallelized across the MPI processes. Here on 4 GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# free up memory if necessary\n",
    "try:\n",
    "    del x, y, z\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "n, m = 4000, 4000\n",
    "x = ht.random.randn(n, m, split=0, device=\"gpu\") # distributed RNG\n",
    "y = ht.random.randn(m, n, split=None, device=\"gpu\")\n",
    "z =  x @ y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ht.linalg.matmul` or `@` breaks down the matrix multiplication into a series of smaller `torch` matrix multiplications, which are then distributed across the MPI processes. This operation can be very communication-intensive on huge matrices that both require distribution, and users should choose the `split` axis carefully to minimize communication overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with sizes and the `split` parameter (distribution axis) for both matrices and time the result. Note that:\n",
    "- If you set **`split=None` for both matrices**, each process (in this case, each GPU) will attempt to multiply the entire matrices. Depending on the matrix sizes, the GPU memory might be insufficient. (And if you can multiply the matrices on a single GPU, it's much more efficient to stick to PyTorch's `torch.linalg.matmul` function.)\n",
    "- If **`split` is not None for both matrices**, each process will only hold a slice of the data, and will need to communicate data with other processes in order to perform the multiplication. This **introduces huge communication overhead**, but allows you to perform the multiplication on larger matrices than would fit in the memory of a single GPU.\n",
    "- If **`split` is None for one matrix and not None for the other**, the multiplication does not require communication, and the result will be distributed. If your data size allows it, you should always favor this option.\n",
    "\n",
    "Time the multiplication for different split parameters and see how the performance changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] The slowest run took 15.33 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "2.78 ms ± 2.76 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] The slowest run took 14.90 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "2.69 ms ± 2.65 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] The slowest run took 14.88 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "2.22 ms ± 2.24 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] The slowest run took 14.81 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
       "2.7 ms ± 2.66 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "z = %timeit -n 1 -r 5 x @ y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat supports many linear algebra operations:\n",
    "```bash\n",
    ">>> ht.linalg.\n",
    "ht.linalg.basics        ht.linalg.hsvd_rtol(    ht.linalg.projection(   ht.linalg.triu(\n",
    "ht.linalg.cg(           ht.linalg.inv(          ht.linalg.qr(           ht.linalg.vdot(\n",
    "ht.linalg.cross(        ht.linalg.lanczos(      ht.linalg.solver        ht.linalg.vecdot(\n",
    "ht.linalg.det(          ht.linalg.matmul(       ht.linalg.svdtools      ht.linalg.vector_norm(\n",
    "ht.linalg.dot(          ht.linalg.matrix_norm(  ht.linalg.trace(        \n",
    "ht.linalg.hsvd(         ht.linalg.norm(         ht.linalg.transpose(    \n",
    "ht.linalg.hsvd_rank(    ht.linalg.outer(        ht.linalg.tril(         \n",
    "```\n",
    "\n",
    "and a lot more is in the works, including distributed eigendecompositions, SVD, and more. If the operation you need is not yet supported, leave us a note [here](https://github.com/helmholtz-analytics/heat/issues) and we'll get back to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can of course perform all operations on CPUs. You can leave out the `device` attribute entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interoperability\n",
    "\n",
    "We can easily create DNDarrays from PyTorch tensors and numpy ndarrays. We can also convert DNDarrays to PyTorch tensors and numpy ndarrays. This makes it easy to integrate Heat into existing PyTorch and numpy workflows. Here a basic example with xarrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n",
      "\u001b[1;32m      3\u001b[0m local_xr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(dndarray\u001b[38;5;241m.\u001b[39mlarray, dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# proceed with local xarray operations\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xarray'\n",
      "[2:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n",
      "\u001b[1;32m      3\u001b[0m local_xr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(dndarray\u001b[38;5;241m.\u001b[39mlarray, dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# proceed with local xarray operations\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xarray'\n",
      "[1:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n",
      "\u001b[1;32m      3\u001b[0m local_xr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(dndarray\u001b[38;5;241m.\u001b[39mlarray, dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# proceed with local xarray operations\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xarray'\n",
      "[3:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n",
      "\u001b[1;32m      3\u001b[0m local_xr \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(dndarray\u001b[38;5;241m.\u001b[39mlarray, dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# proceed with local xarray operations\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xarray'\n"
     ]
    },
    {
     "ename": "AlreadyDisplayedError",
     "evalue": "4 errors",
     "output_type": "error",
     "traceback": [
      "4 errors"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import xarray as xr\n",
    "\n",
    "local_xr = xr.DataArray(dndarray.larray, dims=(\"z\", \"y\", \"x\"))\n",
    "# proceed with local xarray operations\n",
    "local_xr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** this is not a distributed `xarray`, but local xarray objects on each rank.\n",
    "Work on [expanding xarray support](https://github.com/helmholtz-analytics/heat/pull/1183) is ongoing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat will try to reuse the memory of the original array as much as possible. If you would prefer a copy with different memory, the ```copy``` keyword argument can be used when creating a DNDArray from other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] tensor([-1,  1,  2,  3,  4])\n",
       "tensor([0, 1, 2, 3, 4])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] tensor([-1,  1,  2,  3,  4])\n",
       "tensor([0, 1, 2, 3, 4])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] tensor([-1,  1,  2,  3,  4])\n",
       "tensor([0, 1, 2, 3, 4])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] tensor([-1,  1,  2,  3,  4])\n",
       "tensor([0, 1, 2, 3, 4])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import torch\n",
    "torch_array = torch.arange(5)\n",
    "heat_array = ht.array(torch_array, copy=False)\n",
    "heat_array[0] = -1\n",
    "print(torch_array)\n",
    "\n",
    "torch_array = torch.arange(5)\n",
    "heat_array = ht.array(torch_array, copy=True)\n",
    "heat_array[0] = -1\n",
    "print(torch_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interoperability is a key feature of Heat, and we are constantly working to increase Heat's compliance to the [Python array API standard](https://data-apis.org/array-api/latest/). As usual, please [let us know](https://github.com/helmholtz-analytics/heat/issues) if you encounter any issues or have any feature requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [next notebook](2_internals.ipynb), let's have a look at Heat's most important internal functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heat-dev311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
