{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HeAT Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by the [CS228 tutorial](https://github.com/kuleshov/cs228-material/blob/master/tutorials/python/cs228-python-tutorial.ipynb) from Volodomyr Kuleshov and Isaac Caswell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "<div style=\"float: right; padding-right: 2em; padding-top: 2em;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/master/doc/images/logo_HeAT.png\"></img>\n",
    "</div>\n",
    "\n",
    "* [Installation](#Installation)\n",
    "    * [Dependencies](#Dependencies)\n",
    "    * [Dependencies](#Dependencies)\n",
    "* [HeAT Arrays](#HeAT-Arrays)\n",
    "    * [Data Types](#Data-Types)\n",
    "    * [Operations](#Operations)\n",
    "    * [Indexing](#Indexing)\n",
    "* [Parallel Processing](#Parallel-Processing)\n",
    "    * [GPUs](#Dependencies)\n",
    "    * [Distributed Computing](#Distributed-Computing)\n",
    "    * [Parallel Interactive Interpreter](#Parallel-Interactive-Interpreter)\n",
    "    * [Dos and Don'ts](#Dos-and-Don'ts)\n",
    "\n",
    "HeAT is a flexible and seamless open-source software for high performance data analytics and machine learnings. It provides highly optimized algorithms and data structures for multi-dimensional arrays computations using CPUs, GPUs and distributed cluster systems. The goal of HeAT is to fill the gap between data analytics and machine learning libraries with a strong focus on on single-node performance, and traditional high-performance computing (HPC). HeAT's generic Python-first programming interface integrates seamlessly with the existing data science ecosystem and makes it as effortless as using numpy to write scalable scientific and data science applications that go beyond the computational and memory needs of your laptop and desktop.\n",
    "\n",
    "For this tutorial, we assume that you are somewhat proficient in the Python programming language. Equally, it is beneficial that you have worked with vectorized multi-dimensional array data structures before, as offered by NumPy, Matlab or R for example. If not or you feel like refreshing your knowledge, you might find the following ressources useful: [CS228 Python and NumPy Tutorial](https://github.com/kuleshov/cs228-material/blob/master/tutorials/python/cs228-python-tutorial.ipynb), [NumPy for MATLAB users](https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html) and [NumPy for R users](http://mathesaurus.sourceforge.net/r-numpy.html)\n",
    "\n",
    "In line with this tutorial, we will cover the following topics\n",
    "\n",
    "* Installation and setup of HeAT\n",
    "* Working with HeAT arrays, operations, indexing etc.\n",
    "* Utilizing HeAT's scalable parallel processing capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "---\n",
    "\n",
    "In most use cases the best way to install HeAT on your system is to use the official pre-built package from the Python Package index (PyPi) as follow.\n",
    "\n",
    "```bash\n",
    "python -m pip install heat\n",
    "```\n",
    "\n",
    "You might need to use the `--user` flag or a [virtual environment](https://docs.python.org/3/library/venv.html) on systems where you do not have sufficient priviliges.\n",
    "\n",
    "You can also install the latest greatest HeAT version by cloning the HeAT source code repository and a manual installation.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/helmholtz-analytics/heat && cd heat && pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "HeAT requires you to have an [MPI](https://computing.llnl.gov/tutorials/mpi/) installation on your system in order to enable parallel processing capabilities. If not already present on your system (also applies to laptops, desktops etc.) you can obtain it through your systems package manager (here: OpenMPI), e.g.:\n",
    "\n",
    "```bash\n",
    "apt-get install libopenmpi-dev (Ubuntu, Debian)\n",
    "dnf install openmpi-devel (Fedora)\n",
    "yum install openmpi-devel (CentOS)\n",
    "```\n",
    "\n",
    "Installing these dependencies usually requires administrator priviliges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Features\n",
    "\n",
    "HeAT may be installed with several optional features, i.e. GPU support on top of CUDA, HDF5 and NetCDF4 (parallel) I/O. If you feel like using these features, this how you can enable them\n",
    "\n",
    "* GPU support—ensure that CUDA is installed on your system. You may find an installation guide [here](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html).\n",
    "* HDF5 support—install HDF5 via your system's package manager, preferably with parallel I/O capabilities\n",
    "\n",
    "```bash\n",
    "apt-get install libhdf5-openmpi-dev (Ubuntu, Debian)\n",
    "dnf install hdf5-openmpi-devel (Fedora)\n",
    "yum install hdf5-openmpi-devel (CentOS)\n",
    "```\n",
    "\n",
    "* NetCDF4 support—install NetCDF4 via your system's package manager, preferably with parallel I/O capabilities\n",
    "\n",
    "```bash\n",
    "apt-get install libnetcdf-dev (Ubuntu, Debian)\n",
    "dnf install netcdf-openmpi-devel (Fedora)\n",
    "yum install netcdf-openmpi-devel (CentOS)\n",
    "```\n",
    "\n",
    "When you install HeAT you need to explicitly state that you also want to install all modules for HDF5 and NetCDF4 support by specifying an extras flag, i.e.:\n",
    "\n",
    "```bash\n",
    "pip install -e .[hdf5,netcdf] heat\n",
    "```\n",
    "\n",
    "respectively\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/helmholtz-analytics/heat && cd heat && pip install -e [hdf5,netcdf] .\n",
    "```\n",
    "\n",
    "It is possible to only install either HDF5 or NetCDF4 support by leaving out the respective extra dependency in the above command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeAT Arrays\n",
    "---\n",
    "\n",
    "To be able to start working with HeAT, we first have to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heat as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to a NumPy array, a HeAT array is a grid of values, all of identical type. The number of dimensions is the rank of the array, while the shape of an array is a tuple of integers giving the number of elements of the array along each dimension. \n",
    "\n",
    "HeAT tries to mimic NumPy's API as closely as possible, allowing to use well-known array creation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.ones((4, 5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 9.],\n",
       "        [9., 9.],\n",
       "        [9., 9.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.full((3, 2,), fill_value=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "HeAT supports several different data types and operation to retrieve and manipulate the type of a HeAT array. However, in contrast to NumPy, HeAT limits itself to logical (bool) and numerical types only (uint8, int16/32/64 and float32/64). \n",
    "\n",
    "**NOTE:** by default HeAT will allocate floating-point values in single-precision only, due to a much higher processing performance on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]), heat.core.types.float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.zeros((3, 4,))\n",
    "a, a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]), heat.core.types.int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.astype(ht.int64)\n",
    "b, b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.zeros((3, 4,), dtype=ht.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "\n",
    "HeAT supports several mathematical operations, ranging from simple element-wise functions, binary arithmetic operations, linear algebra to powerful reductions. Operations are by default performed on the entire values or along one or more dimensions of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ht.full((3, 4,), 8)\n",
    "b = ht.ones((3, 4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 9., 9., 9.],\n",
       "        [9., 9., 9., 9.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 7., 7.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.sub(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.8415,  0.9093,  0.1411, -0.7568], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.arange(5).sin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 8., 8.],\n",
       "        [8., 8., 8.],\n",
       "        [8., 8., 8.],\n",
       "        [8., 8., 8.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.],\n",
       "        [4.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "HeAT implements the same broadcasting rules (implicit repition of an operation when the rank/shape of the operands do not match) as NumPy does, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.arange(10) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([0, 1, 2, 3], dtype=torch.int32),\n",
       " tensor([[1., 2., 3., 4.],\n",
       "         [1., 2., 3., 4.],\n",
       "         [1., 2., 3., 4.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.ones((3, 4,))\n",
    "b = ht.arange(4)\n",
    "c = a + b\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "HeAT allows to index arrays and thereby extracting a partial view of the elements in an array. It is possible to get obtain single values as well as entire chunks, called slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.arange(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, dtype=torch.int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6], dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "\n",
    "HeAT is extensively documented. You may find the online API reference on Read the Docs: [HeAT Documentation](https://heat.readthedocs.io/). It is also possible to look up the docs in an interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sum in module heat.core.arithmetics:\n",
      "\n",
      "sum(x, axis=None, out=None, keepdim=None)\n",
      "    Sum of array elements over a given axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : ht.DNDarray\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis along which a sum is performed. The default, axis=None, will sum\n",
      "        all of the elements of the input array. If axis is negative it counts\n",
      "        from the last to the first axis.\n",
      "    \n",
      "        If axis is a tuple of ints, a sum is performed on all of the axes specified\n",
      "        in the tuple instead of a single axis or all the axes as before.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    sum_along_axis : ht.DNDarray\n",
      "        An array with the same shape as self.__array except for the specified axis which\n",
      "        becomes one, e.g. a.shape = (1, 2, 3) => ht.ones((1, 2, 3)).sum(axis=1).shape = (1, 1, 3)\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> ht.sum(ht.ones(2))\n",
      "    tensor([2.])\n",
      "    \n",
      "    >>> ht.sum(ht.ones((3,3)))\n",
      "    tensor([9.])\n",
      "    \n",
      "    >>> ht.sum(ht.ones((3,3)).astype(ht.int))\n",
      "    tensor([9])\n",
      "    \n",
      "    >>> ht.sum(ht.ones((3,2,1)), axis=-3)\n",
      "    tensor([[[3.],\n",
      "             [3.]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ht.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing\n",
    "---\n",
    "\n",
    "HeAT actual power lies in the possibility to exploit the processing performance of modern accelerator hardware (GPUs) as well as distributed (high-performance) cluster systems. By itself all operations executed on CPUs are to large extent vectorized (AVX) and thread-parallelized (OpenMP). We utilize CUDA to process data on GPUs, requiring you to have a suitable nVidia device and the Message Passing Interface (MPI) for distributed computations.\n",
    "\n",
    "**NOTE:** The GPU examples below will only properly execute on a computer with a CUDA GPU. Make sure to either start the notebook on an appropriate machine or copy and paste the examples into a script and execute it on a suitable device.\n",
    "\n",
    "**NOTE: ** All examples below explaining the distributed processing capabilities need to be executed outside this notebook in a separate MPI-capable environment. We suggest to copy and paste the code snippets into a script and execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUs\n",
    "\n",
    "HeAT's array creation functions all support an additional parameter that allow to place the data on a specific device. By default, the CPU is selected, but it is also possible to directly allocate the data on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.zeros((3,4,), device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays on the same device can be seemlessly used in any heat operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5.]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.zeros((3,4,), device='gpu')\n",
    "b = ht.ones((3,4,), device='gpu')\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, performing operations on arrays with mismatching device will purposefully result result in an error (due to potentially large copy overhead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected type torch.FloatTensor but got torch.cuda.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                                  Traceback (most recent call last)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected type torch.FloatTensor but got torch.cuda.FloatTensor"
     ]
    }
   ],
   "source": [
    "a = ht.full((3,4,), 4, device='cpu')\n",
    "b = ht.ones((3,4,), device='gpu')\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible, though, to explicitly move an array from one device to the other and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.full((3,4,), 4, device='gpu')\n",
    "a.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing code for GPUs only, you might quickly find it tedious to explicitly place every on the GPU by specifying the `device=` parameter. Hence, it is possible to set a default backend on which HeAT will work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.use_backend('gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Computing\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/master/doc/images/heat_split_array.png\" width=\"40%\"></img>\n",
    "\n",
    "**NOTE: ** In the following we will use a `(<mpi_rank>/<mpi_size>)` prefix on each output to clearly show, what each individual process is printing. In actual application you would not observe this behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Interactive Interpreter\n",
    "\n",
    "HeAT allows you to interactively program and debug distributed code. The root process will spawn an interactive shell, that forwards the inputs to all other ranks and equally collects the output of all nodes. The interactive interpreter can be found in the HeAT sources in the path `scripts/interactive.py` or can be download like this `wget https://raw.githubusercontent.com/helmholtz-analytics/heat/master/scripts/interactive.py`.\n",
    "\n",
    "You can start the interactive interpreter by invoking the following command. The `-s all` flag must be passed to the interpeter for it to work.\n",
    "\n",
    "```bash\n",
    "mpirun -s all -np <procs> python interactive.py\n",
    "```\n",
    "\n",
    "**NOTE: ** the interactive interpreter unfortunately does not support the full set of control commands, disallowing 'arrow-up' command repetition for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dos and Don'ts\n",
    "\n",
    "In this section we would like to address a few best practices for programming with HeAT. While we can obviously not cover all issues, these are major pointers as how to get reasonable performance.\n",
    "\n",
    "**Dos**\n",
    "\n",
    "* Split up large data amounts\n",
    "    * often you input data set along the 'observations/samples' dimension\n",
    "    * large intermediate matrices\n",
    "* Use the HeAT API\n",
    "    * computational kernels are optimized\n",
    "    * Python constructs (e.g. loops) tend to be slow\n",
    "\n",
    "**Dont's**\n",
    "\n",
    "* Avoid extensive data copying, e.g.\n",
    "    * operations with operands of different splits (except None)\n",
    "    * reshape() that actually change the array dimensions (adding extra dimensions with size 1 is fine)\n",
    "* Execute everything on GPU\n",
    "    * computation-intensive operations are usually a good fit\n",
    "    * operations extensively accessing memory only (e.g. sorting) are not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heat_kernel",
   "language": "python",
   "name": "heat_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
